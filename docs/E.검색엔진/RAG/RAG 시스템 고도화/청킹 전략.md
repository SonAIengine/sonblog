ë¬¸ì„œ ì „ì²˜ë¦¬ëŠ” RAG(Retrieval-Augmented Generation) ì‹œìŠ¤í…œì—ì„œ í•µì‹¬ì ì¸ ì „ì²˜ë¦¬ ê³¼ì • ì¤‘ í•˜ë‚˜ì´ë‹¤. ì´ ë‹¨ê³„ëŠ” ì›ë³¸ ë¬¸ì„œë¥¼ ê²€ìƒ‰ê³¼ ìƒì„±ì— ì í•©í•œ í˜•íƒœë¡œ ê°€ê³µí•˜ì—¬, ê²€ìƒ‰ ì •í™•ë„ì™€ ìƒì„± í’ˆì§ˆì„ ëª¨ë‘ í–¥ìƒì‹œí‚¤ëŠ” ë° ëª©ì ì´ ìˆë‹¤.

## ë¬¸ì„œ ë¶„í• (ì²­í‚¹, Chunking)ì˜ ì¤‘ìš”ì„±

ë¬¸ì„œ ë¶„í• ì€ ì „ì²˜ë¦¬ì˜ í•µì‹¬ìœ¼ë¡œ, ê¸´ ë¬¸ì„œë¥¼ ì‘ê³  ìœ ì˜ë¯¸í•œ ë‹¨ìœ„ë¡œ ë‚˜ëˆ„ëŠ” ì‘ì—…ì´ë‹¤. ì´ ê³¼ì •ì€ ì •ë³´ ê²€ìƒ‰ ì •í™•ë„, ë¬¸ë§¥ ë³´ì¡´, ìƒì„± íš¨ìœ¨ì„±ì— ì§ê²°ëœë‹¤. ì ì ˆí•˜ê²Œ ë‚˜ëˆˆ ì²­í¬ëŠ” ìœ ì‚¬ë„ ê²€ìƒ‰ì˜ ì •ë°€ë„ë¥¼ ë†’ì´ê³ , LLMì´ ë¶€ë‹´ ì—†ì´ ë¬¸ë§¥ì„ ì´í•´í•˜ê²Œ í•˜ì—¬ ì‘ë‹µ í’ˆì§ˆì„ ë†’ì´ëŠ” ë° ê¸°ì—¬í•œë‹¤.

### ë¬¸ì ìˆ˜ ê¸°ë°˜ ë¶„í• ì˜ í•œê³„

ê°€ì¥ ë‹¨ìˆœí•œ ë°©ì‹ì€ **ë¬¸ì ìˆ˜ ê¸°ë°˜ ë¶„í• **ì´ë‹¤. ì´ëŠ” ì¼ì •í•œ ê¸¸ì´ë§ˆë‹¤ í…ìŠ¤íŠ¸ë¥¼ ìë¥´ëŠ” ë°©ì‹ìœ¼ë¡œ êµ¬í˜„ì´ ë§¤ìš° ê°„ë‹¨í•˜ê³  ì†ë„ê°€ ë¹ ë¥´ë‹¤. ê·¸ëŸ¬ë‚˜ ë¬¸ì¥ êµ¬ì¡°ë‚˜ ì˜ë¯¸ íë¦„ì„ ê³ ë ¤í•˜ì§€ ì•Šê¸° ë•Œë¬¸ì— ë‹¤ìŒê³¼ ê°™ì€ ë¬¸ì œê°€ ìˆë‹¤.

- í•µì‹¬ ì •ë³´ê°€ ì˜ë ¤ì„œ ê²€ìƒ‰ ì‹œ ëˆ„ë½ ê°€ëŠ¥
    
- ë¬¸ë§¥ì´ ëŠê²¨ ìƒì„± ì‘ë‹µì´ ì–´ìƒ‰í•´ì§ˆ ìˆ˜ ìˆìŒ
    
- ë¬¸ì„œì— ë”°ë¼ ìµœì ì˜ ë¶„í• ì´ ë˜ì§€ ì•ŠìŒ

## ë¶€ëª¨-ìì‹ ë¶„í• (Parent-Child Chunking)ì˜ ê°œìš”

ë³´ë‹¤ êµ¬ì¡°í™”ëœ ë°©ì‹ìœ¼ë¡œ ë¬¸ì„œë¥¼ ë¶„í• í•˜ê¸° ìœ„í•œ ì „ëµì´ **ë¶€ëª¨-ìì‹ ë¶„í• **ì´ë‹¤. ì´ ë°©ì‹ì€ ë‹¨ìˆœíˆ í…ìŠ¤íŠ¸ ê¸¸ì´ë§Œ ê³ ë ¤í•˜ì§€ ì•Šê³  ë¬¸ì„œì˜ ê³„ì¸µ êµ¬ì¡°ë¥¼ ë³´ì¡´í•˜ë©´ì„œë„, ê²€ìƒ‰ íš¨ìœ¨ì„±ê³¼ ë¬¸ë§¥ ì´í•´ë„ë¥¼ ë™ì‹œì— ì¶”êµ¬í•˜ëŠ” ë°©ì‹ì´ë‹¤.

### ê¸°ë³¸ ê°œë…

ë¶€ëª¨-ìì‹ ë¶„í• ì€ ë¬¸ì„œë¥¼ ë‘ ë‹¨ê³„ë¡œ ë‚˜ëˆˆë‹¤.

1. **ë¶€ëª¨ ë¬¸ì„œ(Parent Chunk)**: ì¥, ì ˆ, í° ë‹¨ë½ ë“± ë¬¸ì„œì˜ ì£¼ìš” êµ¬íš ê¸°ì¤€ìœ¼ë¡œ ë‚˜ëˆˆ í° ë‹¨ìœ„
    
2. **ìì‹ ë¬¸ì„œ(Child Chunk)**: ê° ë¶€ëª¨ ë¬¸ì„œì—ì„œ ë‹¤ì‹œ ì˜ë¯¸ ë‹¨ìœ„ë¡œ ì„¸ë¶„í™”ëœ ì‘ì€ ì²­í¬
    

ì´ë¡œì¨ ì›ë³¸ â†’ ë¶€ëª¨ â†’ ìì‹ì˜ 3ë‹¨ê³„ êµ¬ì¡°ê°€ í˜•ì„±ë˜ë©°, ìì‹ì€ ë¶€ëª¨ì— ì†í•œë‹¤ëŠ” ê´€ê³„ë¥¼ ë©”íƒ€ë°ì´í„°ë¡œ ëª…ì‹œí•œë‹¤.

## ë¶€ëª¨-ìì‹ ë¶„í• ì˜ í•µì‹¬ ì¥ì 

1. **ì •í™•í•œ ì •ë³´ ê²€ìƒ‰**  
    ê²€ìƒ‰ì€ ìì‹ ì²­í¬ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ìˆ˜í–‰ëœë‹¤. ìì‹ì€ ì„¸ë¶„í™”ëœ ì •ë³´ë¥¼ í¬í•¨í•˜ê³  ìˆì–´ ì‚¬ìš©ì ì¿¼ë¦¬ì™€ ë†’ì€ ê´€ë ¨ë„ë¥¼ ê°€ì§ˆ ê°€ëŠ¥ì„±ì´ í¬ë‹¤. ë”°ë¼ì„œ ëŒ€ìš©ëŸ‰ ë¬¸ì„œì—ì„œë„ ëª©í‘œ ì •ë³´ë¥¼ ë¹ ë¥´ê²Œ ì°¾ì„ ìˆ˜ ìˆë‹¤.
    
2. **ë„“ì€ ë¬¸ë§¥ ì œê³µ**  
    ê²€ìƒ‰ëœ ìì‹ ì²­í¬ì— ì—°ê²°ëœ ë¶€ëª¨ ë¬¸ì„œë¥¼ í•¨ê»˜ ë°˜í™˜í•¨ìœ¼ë¡œì¨, ì •ë³´ì˜ â€˜ë§¥ë½â€™ì„ ìƒì§€ ì•Šê²Œ í•œë‹¤. ì´ë¡œì¨ LLMì´ ë” í’ë¶€í•˜ê³  ìì—°ìŠ¤ëŸ¬ìš´ ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ìˆë‹¤.

## ì¸ë±ì‹± ê³¼ì •

1. **ë¬¸ì„œ ë¶„í• **  
    ë¬¸ì„œë¥¼ ë¶€ëª¨ ë‹¨ìœ„ë¡œ ë¨¼ì € ë‚˜ëˆˆ í›„, ê° ë¶€ëª¨ ë‹¨ìœ„ë¥¼ ìì‹ ì²­í¬ë¡œ ë¶„í• í•œë‹¤. ì´ë•Œ ì˜ë¯¸ ê¸°ë°˜ ë¶„í•  ì•Œê³ ë¦¬ì¦˜ì„ í™œìš©í•  ìˆ˜ ìˆë‹¤.
    
2. **ë©”íƒ€ë°ì´í„° í• ë‹¹**  
    ìì‹ ì²­í¬ì—ëŠ” ì–´ë–¤ ë¶€ëª¨ ë¬¸ì„œì— ì†í•˜ëŠ”ì§€ ì‹ë³„í•  ìˆ˜ ìˆëŠ” IDë¥¼ ë©”íƒ€ë°ì´í„°ë¡œ í¬í•¨ì‹œí‚¨ë‹¤.
    
3. **ë²¡í„° ì €ì¥ì†Œì™€ ë¬¸ì„œ ì €ì¥ì†Œ ë¶„ë¦¬**
    
    - ìì‹ ë¬¸ì„œëŠ” ì„ë² ë”©ì„ í†µí•´ ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥ëœë‹¤.
        
    - ë¶€ëª¨ ë¬¸ì„œëŠ” ë³„ë„ì˜ ë¬¸ì„œ ì €ì¥ì†Œì— ì›í˜• ê·¸ëŒ€ë¡œ ë³´ê´€ëœë‹¤.

## ê²€ìƒ‰ íë¦„

1. ì‚¬ìš©ìê°€ ì¿¼ë¦¬ë¥¼ ì…ë ¥í•˜ë©´, ì¿¼ë¦¬ì— ê°€ì¥ ìœ ì‚¬í•œ **ìì‹ ë¬¸ì„œ**ë¥¼ ë²¡í„° DBì—ì„œ ê²€ìƒ‰í•œë‹¤.
    
2. ê²€ìƒ‰ëœ ìì‹ ë¬¸ì„œì˜ **ë¶€ëª¨ ID**ë¥¼ í†µí•´ í•´ë‹¹ **ë¶€ëª¨ ë¬¸ì„œ**ë¥¼ ì°¾ëŠ”ë‹¤.
    
3. ì‚¬ìš©ìì—ê²Œ ë°˜í™˜ë˜ëŠ” ë¬¸ì„œëŠ” ìì‹ì´ ì•„ë‹Œ **ë¶€ëª¨ ë¬¸ì„œ**ì´ë‹¤.

ì´ ê³¼ì •ì„ í†µí•´ ì‹œìŠ¤í…œì€ ì •ë³´ì˜ ì •ë°€ì„±ê³¼ ë¬¸ë§¥ì˜ í’ë¶€í•¨ì„ ë™ì‹œì— í™•ë³´í•  ìˆ˜ ìˆë‹¤.

## ì˜ë¯¸ ê¸°ë°˜ ë¶„í• ê³¼ì˜ ê´€ê³„

ë¶€ëª¨-ìì‹ ë¶„í• ì€ ì˜ë¯¸ ê¸°ë°˜ ë¶„í• ì„ ëŒ€ì²´í•˜ëŠ” ê²ƒì´ ì•„ë‹ˆë‹¤. ì˜¤íˆë ¤ ìƒí˜¸ ë³´ì™„ì ì´ë‹¤. ì˜ˆë¥¼ ë“¤ì–´ ìì‹ ì²­í¬ë¥¼ ë‚˜ëˆŒ ë•Œ ì˜ë¯¸ ë‹¨ìœ„ ë¶„í• ì„ ì ìš©í•˜ë©´, ë” ìì—°ìŠ¤ëŸ½ê³  ì‘ë‹µ í’ˆì§ˆì´ ë†’ì€ ê²°ê³¼ë¥¼ ìœ ë„í•  ìˆ˜ ìˆë‹¤.


## ì˜ˆì‹œ ì½”ë“œ

```python
import os
from dotenv import load_dotenv
from docx import Document as DocxDocument
from langchain.schema import Document
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import FAISS
from langchain.retrievers import ParentDocumentRetriever
from langchain.storage import InMemoryStore

# 1. í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()
api_key = os.getenv("OPENAI_API_KEY")
if not api_key:
    raise EnvironmentError("OPENAI_API_KEYê°€ .envì— ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

# 2. ë¬¸ì„œ ë¡œë”© í•¨ìˆ˜
def load_docx_as_text(path: str) -> str:
    doc = DocxDocument(path)
    return "\n".join([para.text.strip() for para in doc.paragraphs if para.text.strip()])

# 3. ì›ë³¸ ë¬¸ì„œ ë¡œë“œ
docx_path = "data/26. í”Œë˜í‹°ì–´ ê°€ì´ë“œë¶_2025_ìµœì‹ _250610.docx"
raw_text = load_docx_as_text(docx_path)
raw_documents = [Document(
    page_content=raw_text,
    metadata={"source": docx_path, "title": "í”Œë˜í‹°ì–´ ê°€ì´ë“œë¶"}
)]

# 4. ë¶„í• ê¸° ì •ì˜
parent_splitter = RecursiveCharacterTextSplitter(
    chunk_size=2000,
    chunk_overlap=200,
    separators=["\n\n", "\n", "â–¶", "01 ", "02 ", "03 ", "04 ", "05 ", "06 ", "07 ", "08 ", "09 ", " ", ""]
)

child_splitter = RecursiveCharacterTextSplitter(
    chunk_size=400,
    chunk_overlap=50,
    separators=["\n\n", "\n", "â–¶", " ", ""]
)

# 5. ì„ë² ë”© ë° ë²¡í„°ìŠ¤í† ì–´ ì´ˆê¸°í™”
embedding = OpenAIEmbeddings(openai_api_key=api_key)
vectorstore = FAISS.from_texts(["dummy"], embedding=embedding)
vectorstore.delete([vectorstore.index_to_docstore_id[0]])
store = InMemoryStore()

# 6. ParentDocumentRetriever ì„¤ì •
retriever = ParentDocumentRetriever(
    vectorstore=vectorstore,
    docstore=store,
    parent_splitter=parent_splitter,
    child_splitter=child_splitter,
    k=4
)

# 7. ìƒ‰ì¸ ìˆ˜í–‰
retriever.add_documents(raw_documents)

```

`separators`ëŠ” `RecursiveCharacterTextSplitter`ê°€ í…ìŠ¤íŠ¸ë¥¼ **ì²­í¬(chunk)** ë¡œ ë‚˜ëˆŒ ë•Œ **ìš°ì„ ì ìœ¼ë¡œ ì‚¬ìš©í•˜ëŠ” êµ¬ë¶„ìë“¤**ì„ ì˜ë¯¸í•©ë‹ˆë‹¤.  
ì¦‰, ë¶„í•  ì‹œ ê°€ëŠ¥í•œ í•œ ì˜ë¯¸ ë‹¨ìœ„ë¥¼ ìœ ì§€í•˜ë©´ì„œ í…ìŠ¤íŠ¸ë¥¼ ë‚˜ëˆ„ê¸° ìœ„í•´ ì‚¬ìš©í•˜ëŠ” **ìš°ì„ ìˆœìœ„ ë¶„í•  ê¸°ì¤€ ë¦¬ìŠ¤íŠ¸**ì…ë‹ˆë‹¤.

`RecursiveCharacterTextSplitter`ëŠ” ë‹¤ìŒê³¼ ê°™ì€ ë°©ì‹ìœ¼ë¡œ ì‘ë™í•©ë‹ˆë‹¤.

1. `separators` ë¦¬ìŠ¤íŠ¸ì— ì •ì˜ëœ ìˆœì„œëŒ€ë¡œ ì‹œë„í•©ë‹ˆë‹¤.
    
2. í…ìŠ¤íŠ¸ë¥¼ `chunk_size` ì´ë‚´ë¡œ ë‚˜ëˆŒ ìˆ˜ ìˆëŠ” êµ¬ë¶„ìë¥¼ ì°¾ìŠµë‹ˆë‹¤.
    
3. **í•´ë‹¹ êµ¬ë¶„ìë¡œ ë‚˜ëˆ´ì„ ë•Œ ì›í•˜ëŠ” í¬ê¸° ì´í•˜ë¡œ ì˜ ë¶„í• ë˜ë©´ ì„±ê³µ**, ê·¸ë ‡ì§€ ì•Šìœ¼ë©´ ê·¸ë‹¤ìŒ êµ¬ë¶„ìë¡œ ì‹œë„í•©ë‹ˆë‹¤.
    
4. ëª¨ë“  êµ¬ë¶„ìë¡œë„ ì›í•˜ëŠ” í¬ê¸°ë¡œ ë¶„í• ì´ ì•ˆ ë˜ë©´, ë§ˆì§€ë§‰ ìˆ˜ë‹¨ìœ¼ë¡œ ë¬¸ì¥ì„ ì¤‘ê°„ì—ì„œ ì˜ë¼ ë‚˜ëˆ•ë‹ˆë‹¤.
    

---

### ì˜ˆì‹œ

```python
separators=["\n\n", "\n", "â–¶", " ", ""]
```

ì´ ì˜ë¯¸ëŠ”:

- **ê°€ì¥ ìš°ì„ ìˆœìœ„ëŠ” `\n\n`** â†’ ë¬¸ë‹¨ ë‹¨ìœ„ ë¶„í• 
    
- ê·¸ë‹¤ìŒ `\n` â†’ ì¤„ë°”ê¿ˆ ê¸°ì¤€
    
- `â–¶` â†’ í•­ëª© êµ¬ë¶„ì (ì˜ˆ: ë©”ë‰´, í¬ì¸íŠ¸ ë“±)
    
- `" "` â†’ ê³µë°± (ë‹¨ì–´ ë‹¨ìœ„)
    
- ë§ˆì§€ë§‰ `""` â†’ ë¬¸ì ë‹¨ìœ„ (ìµœí›„ ìˆ˜ë‹¨)
    

---

### ğŸ’¡ ìš”ì•½

|ìˆœì„œ|êµ¬ë¶„ì|ì˜ë¯¸|ì—­í• |
|---|---|---|---|
|1|`\n\n`|ë¬¸ë‹¨ êµ¬ë¶„ì|ê°€ëŠ¥í•œ í•œ ì˜ë¯¸ ìˆëŠ” ë¬¸ë‹¨ ë‹¨ìœ„ë¡œ ìë¦„|
|2|`\n`|ì¤„ êµ¬ë¶„ì|ë¬¸ì¥ì´ ë°”ë€ŒëŠ” ìœ„ì¹˜ ê¸°ì¤€|
|3|`â–¶`|íŠ¹ìˆ˜ êµ¬ë¶„ì (ëª©ì°¨ ë“±)|ì‚¬ìš©ì ì •ì˜ í¬ì¸íŠ¸ ë˜ëŠ” í† í”½ êµ¬ë¶„|
|4|`" "`|ë‹¨ì–´ êµ¬ë¶„ì|ë‹¨ì–´ ë‹¨ìœ„ë¡œ ì˜ë¼ ìµœëŒ€í•œ ì˜ë¯¸ ìœ ì§€|
|5|`""`|ë¬¸ì ë‹¨ìœ„|ìœ„ ê¸°ì¤€ìœ¼ë¡œë„ ìë¥´ê¸° ì–´ë ¤ìš¸ ë•Œ ë§ˆì§€ë§‰ ì‹œë„|

---

ì´ë ‡ê²Œ í•˜ë©´ ì²­í¬ê°€ ë‹¨ìˆœíˆ ê³ ì •ëœ ê¸¸ì´ë¡œ ì˜ë¦¬ëŠ” ê²ƒì´ ì•„ë‹ˆë¼, **ìì—°ìŠ¤ëŸ¬ìš´ ì˜ë¯¸ ë‹¨ìœ„ë¥¼ ìœ ì§€í•˜ë©´ì„œ ë‚˜ë‰˜ë„ë¡** ìœ ë„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.