### 1. 입력 임베딩 확보 단계
- 문장의 각 토큰을 임베딩 벡터로 변환한 뒤, 위치 인코딩을 더해 입력 행렬 **X**를 준비한다.  
- **X**의 크기는 `n × d_model`이며, *n*은 토큰 수, *d_model*은 모델 차원이다.

### 2. 전용 가중치 행렬 정의 단계
- 쿼리·키·밸류 각각에 대응하는 가중치 행렬 `W_Q`, `W_K`, `W_V`를 학습 가능한 파라미터로 초기화한다.  
- 일반적인 크기는 `d_model × d_h`이며, `d_h`는 헤드별 차원이다.

### 3. 선형 투영 수행 단계
- 입력 행렬 **X**에 각 가중치 행렬을 곱해 세 개의 행렬을 얻는다.  
  - `Q = X · W_Q`  
  - `K = X · W_K`  
  - `V = X · W_V`  
- 이 연산은 완전연결층과 동일하며 GPU 병렬화가 용이하다.

### 4. 멀티 헤드 분할 단계
- 표현 다양성을 위해 `h`개의 헤드로 분리한다.  
- 구현 방식  
  1. **병합 방식**: 한 번의 행렬 곱으로 `Q`, `K`, `V`를 `n × (h·d_k)` 크기로 만든 뒤 마지막 차원을 `(h, d_k)`로 리쉐이프한다.  
  2. **분리 방식**: 헤드마다 고유한 `(W_{Q_i}, W_{K_i}, W_{V_i})`를 두고 독립적으로 투영한다.

### 5. 학습과 업데이트 단계
- `W_Q`, `W_K`, `W_V`는 역전파를 통해 손실 함수의 그래디언트를 받아 지속적으로 갱신된다.  
- 옵티마이저(예: AdamW)가 가중치를 조정하여 토큰 간 의미 관계를 내재화한다.

> 위 절차를 통해 생성된 **Q**, **K**, **V** 행렬은 이후 스케일드 닷 프로덕트 어텐션에 입력되어 문맥 정보를 계산하게 된다.