텍스트 데이터들이 필요하다.

data 딕셔너리의 train 키에서 document 값을 가져와 모든 문서를 하나의 문자열로 합친다.
이렇게 만들어진 전체 텍스트에서 중복을 제거하고 정렬된 고유한 문자 목록을 생성한다.

이 과정을 통해 데이터셋에 존재하는 모든 고유한 한국어 문자를 파악할 수 있다.

그 다음, 이 고유 문자 목록의 길이를 계산해 전체 어휘 크기를 구하고, 총 글자 수를 출력해 데이터셋의 어휘 다양성을 확인합니다.

다음으로, 문자와 인덱스를 매핑하는 딕셔너리를 생성한다. 이러한 매핑은 텍스트 데이터를 숫자로 변환하고 다시 텍스트로 복원하는 데 사용된다.

 `데이터를 텐서로 변환하고 데이터 타입을 long으로 지정하는 과정은 딥러닝 모델의 효율적인 학습과 처리를 위해서 중요하다. 텐서는 딥러닝에서 데이터를 표현하는 기본 단위로, 다차원 배열 형태로 데이터를 저장하고 처리한다. 문자열을 숫자로 인코딩하고 이를 텐서로 변환하는 과정은 모델이 텍스트 데이터를 이해하고 학습할 수 있도록 하는 필수적인 전처리 단계이다.`
 
`데이터 타입을 long으로 지정하는 이유는 주로 텍스트 데이터의 특성과 관련이 있다. 텍스트 데이터를 숫자로 인코딩할 때 각 단어나 토큰에 해당하는 정수 값이 큰 범위를 가질 수 있기 때문이다. long 타입은 32비트 정수형보다 더 큰 범위의 정수를 표현할 수 있어 큰 어휘 사전을 다룰 때 유용하다. 또한, 파이토치의 많은 함수들이 기본적으로 long 타입의 인덱스를 기대하기 때문에 이를 사용하면 추후 처리 과정에서의 호환성을 보장할 수 있다.`

`이러한 텐서 변환과 데이터 타입 지정은 모델이 데이터를 효율적으로 처리하고 GPU를 통한 빠른 연산을 가능하게 함으로써 모델의 성능과 학습 속도에 직접적인 영향을 준다.`

데이터의 타입을 모두 변경한 후, 다음 단계로 train 데이터셋과 test 데이터셋으로 나누는 작업을 수행한다.
이 과정은 머신러닝 모델의 학습과 평가를 위해 매우 중요하다.

데이터를 훈련용과 검증용으로 분리함으로써 모델의 성능을 객관적으로 평가하고 과적합을 방지할 수 있다.
훈련 데이터는 모델을 학습하는 데 사용되며, 검증 데이터는 학습된 모델의 성능을 테스트하는 데 활용된다.

이러한 분리 작업을 통해 모델이 새로운, 보지 못한 데이터에 대해 얼마나 잘 일반화되는지 확인할 수 있다.
데이터 분할 비율은 일반적으로 프로


