---
title: "LangChainê³¼ Qdrant"
description: "QdrantëŠ” ê³ ì„±ëŠ¥ì˜ ë²¡í„° ìœ ì‚¬ë„ ê²€ìƒ‰ ì—”ì§„ìœ¼ë¡œ, REST ë° gRPC APIë¥¼ í†µí•´ ë²¡í„° ì €ì¥, ê²€ìƒ‰, í•„í„°ë§ì„ ì œê³µí•œë‹¤. LangChainì€ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì˜ ì‘ìš©ì„ ìœ„í•œ í”„ë ˆì„ì›Œí¬ë¡œ, ë‹¤ì–‘í•œ ë²¡í„° ì €ì¥ì†Œ(Vector Store)ì™€ì˜ í†µí•©ì„ ì§€ì›í•œë‹¤."
date: 2025-07-16
tags:
  - LangChain
  - ê²€ìƒ‰ì—”ì§„
  - ë²¡í„° ê²€ìƒ‰
  - Qdrant
---

## 1. ê°œìš”

QdrantëŠ” ê³ ì„±ëŠ¥ì˜ ë²¡í„° ìœ ì‚¬ë„ ê²€ìƒ‰ ì—”ì§„ìœ¼ë¡œ, REST ë° gRPC APIë¥¼ í†µí•´ ë²¡í„° ì €ì¥, ê²€ìƒ‰, í•„í„°ë§ì„ ì œê³µí•œë‹¤. LangChainì€ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì˜ ì‘ìš©ì„ ìœ„í•œ í”„ë ˆì„ì›Œí¬ë¡œ, ë‹¤ì–‘í•œ ë²¡í„° ì €ì¥ì†Œ(Vector Store)ì™€ì˜ í†µí•©ì„ ì§€ì›í•œë‹¤. 

ì´ ë¬¸ì„œì—ì„œëŠ” `langchain-qdrant` ëª¨ë“ˆì„ ì‚¬ìš©í•˜ì—¬ Qdrantë¥¼ LangChainê³¼ ì—°ë™í•˜ê³ , Dense Vector Search, Sparse Vector Search, Hybrid Search, ë©”íƒ€ë°ì´í„° í•„í„°ë§, Retriever ë³€í™˜ ë“±ì˜ ê¸°ëŠ¥ì„ ëª¨ë‘ í™œìš©í•˜ëŠ” ì˜ˆì œë¥¼ ì†Œê°œí•œë‹¤.

## 2. ì‹¤í—˜ í™˜ê²½ ë° ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜

ë‹¤ìŒ í™˜ê²½ì—ì„œ ì‹¤í—˜ì„ ì§„í–‰í•œë‹¤.

- Python 3.12+
    
- Qdrant ì„œë²„: ë¡œì»¬ Docker í™˜ê²½ì—ì„œ ì‹¤í–‰
    
- LangChain ëª¨ë“ˆ: `langchain-openai`, `langchain-qdrant`, `fastembed` ì‚¬ìš©
    

í•„ìˆ˜ íŒ¨í‚¤ì§€ ì„¤ì¹˜ëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤.

```bash
pip install -U langchain-openai langchain-qdrant qdrant-client fastembed
```

## 3. Qdrant ì„œë²„ ì¤€ë¹„

QdrantëŠ” Dockerë¡œ ì‰½ê²Œ ì‹¤í–‰í•  ìˆ˜ ìˆë‹¤. ë¡œì»¬ì—ì„œ ì‹¤í–‰ ì‹œ ë‹¤ìŒ ëª…ë ¹ì–´ë¥¼ ì‚¬ìš©í•œë‹¤.

```bash
docker run -d \
  -p 6333:6333 \
  -v $(pwd)/qdrant_data:/qdrant/storage \
  --name qdrant \
  qdrant/qdrant
```

## 4. LangChain + Qdrant ì—°ë™ ì „ì²´ ì½”ë“œ

ì•„ë˜ ì½”ë“œëŠ” ëª¨ë“  ì£¼ìš” ê¸°ëŠ¥ì„ í¬í•¨í•œ í†µí•© ì˜ˆì œì´ë‹¤. ì´ ì½”ë“œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë‹¤ì–‘í•œ ê²€ìƒ‰ ì‹¤í—˜ì´ ê°€ëŠ¥í•˜ë‹¤.

### 4.1 ì „ì²´ ì½”ë“œ

```python
import os
from uuid import uuid4
from langchain_openai import OpenAIEmbeddings
from langchain_qdrant import QdrantVectorStore, RetrievalMode, FastEmbedSparse
from qdrant_client import QdrantClient, models
from qdrant_client.http.models import Distance, VectorParams, SparseVectorParams
from langchain_core.documents import Document

# 1) ì„ë² ë”©
embeddings = OpenAIEmbeddings(
    model="text-embedding-3-small",
    api_key=os.environ["OPENAI_API_KEY"],
)
sparse_embeddings = FastEmbedSparse(model_name="Qdrant/bm25")

# 2) Qdrant ì—°ê²°
client = QdrantClient(url="http://localhost:6333")

# 3) ì»¬ë ‰ì…˜( dense + sparse ) ìƒì„±
if client.collection_exists("my_documents"):
    client.delete_collection("my_documents")

client.create_collection(
    collection_name="my_documents",
    vectors_config={"dense": VectorParams(size=1536, distance=Distance.COSINE)},
    sparse_vectors_config={"sparse": SparseVectorParams(index=models.SparseIndexParams(on_disk=False))},
)

# 4) ë¬¸ì„œ ì¤€ë¹„
raw_texts = [
    ("I had chocolate chip pancakes and scrambled eggs for breakfast this morning.", "tweet"),
    ("The weather forecast for tomorrow is cloudy and overcast, with a high of 62 degrees Fahrenheit.", "news"),
    ("Building an exciting new project with LangChain - come check it out!", "tweet"),
    ("Robbers broke into the city bank and stole $1 million in cash.", "news"),
    ("Wow! That was an amazing movie. I can't wait to see it again.", "tweet"),
    ("Is the new iPhone worth the price? Read this review to find out.", "website"),
    ("The top 10 soccer players in the world right now.", "website"),
    ("LangGraph is the best framework for building stateful, agentic applications!", "tweet"),
    ("The stock market is down 500 points today due to fears of a recession.", "news"),
    ("I have a bad feeling I am going to get deleted :(", "tweet"),
]
documents = [Document(page_content=t, metadata={"source": s}) for t, s in raw_texts]
uuids = [str(uuid4()) for _ in documents]

# 5) Hybrid ì €ì¥
hybrid_store = QdrantVectorStore(
    client=client,
    collection_name="my_documents",
    embedding=embeddings,
    sparse_embedding=sparse_embeddings,
    retrieval_mode=RetrievalMode.HYBRID,
    vector_name="dense",
    sparse_vector_name="sparse",
)
hybrid_store.add_documents(documents=documents, ids=uuids)

# 6) Dense / Sparse / Hybrid ê²€ìƒ‰ ë° ì¶œë ¥
dense_store = QdrantVectorStore(client, "my_documents", embedding=embeddings,
                                retrieval_mode=RetrievalMode.DENSE, vector_name="dense")
sparse_store = QdrantVectorStore(client, "my_documents", sparse_embedding=sparse_embeddings,
                                 retrieval_mode=RetrievalMode.SPARSE, sparse_vector_name="sparse")

print("ğŸ” Dense ê²€ìƒ‰:", [d.page_content for d in dense_store.similarity_search("LangChain project", k=2)])
print("ğŸ” Sparse ê²€ìƒ‰:", [d.page_content for d in sparse_store.similarity_search("soccer players", k=1)])
print("ğŸ” Hybrid ê²€ìƒ‰:",
      [(d.page_content, f"{s:.6f}") for d, s in hybrid_store.similarity_search_with_score("Will it be hot tomorrow", k=1)])

# 7) Metadata í•„í„°ë§ ê²€ìƒ‰
flt = models.Filter(should=[models.FieldCondition(
    key="page_content",
    match=models.MatchValue(value="The top 10 soccer players in the world right now.")
)])
print("ğŸ” Metadata í•„í„°:", [d.page_content for d in hybrid_store.similarity_search("best soccer players", k=1, filter=flt)])

# 8) ë¬¸ì„œ ì‚­ì œ
hybrid_store.delete(ids=[uuids[-1]])

# 9) Retriever ë³€í™˜
retriever = hybrid_store.as_retriever(search_type="mmr", search_kwargs={"k": 1})
print("ğŸ” Retriever ê²°ê³¼:", [d.page_content for d in retriever.invoke("Stealing from the bank is a crime")])

# 10) Named vector + ì»¤ìŠ¤í…€ í‚¤
QdrantVectorStore.from_documents(
    documents[:2],
    embeddings,
    sparse_embedding=sparse_embeddings,
    location=":memory:",
    collection_name="my_documents_custom",
    content_payload_key="my_page_content",
    metadata_payload_key="my_meta",
    vector_name="custom_vector",
    sparse_vector_name="custom_sparse_vector",
    retrieval_mode=RetrievalMode.HYBRID,
)
print("âœ… ì»¤ìŠ¤í…€ í•„ë“œ ì¸ë±ì‹± ì™„ë£Œ")
```

ì½”ë“œì—ì„œ ìˆ˜í–‰ë˜ëŠ” ì£¼ìš” ê¸°ëŠ¥ë“¤ì€ ë‹¤ìŒê³¼ ê°™ë‹¤.

## 5. ì£¼ìš” ê¸°ëŠ¥ë³„ ì„¤ëª…

### 5.1 Dense Vector Search

Dense ê²€ìƒ‰ì€ ì„ë² ë”©ëœ ë²¡í„° ê°„ì˜ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ë¥¼ ê³„ì‚°í•˜ì—¬ ê°€ì¥ ìœ ì‚¬í•œ ë¬¸ì„œë¥¼ ë°˜í™˜í•œë‹¤. LangChainì—ì„œëŠ” `OpenAIEmbeddings`ë¥¼ í™œìš©í•˜ì—¬ dense ë²¡í„°ë¥¼ ìƒì„±í•˜ê³ , Qdrantì— ì €ì¥ëœ dense ë²¡í„°ì™€ ë¹„êµí•˜ì—¬ ìœ ì‚¬ë„ ê²€ìƒ‰ì„ ìˆ˜í–‰í•œë‹¤.

```python
dense_store.similarity_search("LangChain project", k=2)
```

ê²€ìƒ‰ ê²°ê³¼ëŠ” LLM ê´€ë ¨ ë¬¸ì¥ë“¤ì´ ìš°ì„ ì ìœ¼ë¡œ ë°˜í™˜ë˜ë©°, ì˜ë¯¸ì  ìœ ì‚¬ì„±ì„ ê¸°ë°˜ìœ¼ë¡œ ì •í™•í•œ ê²°ê³¼ë¥¼ ì œê³µí•œë‹¤.

---

### 5.2 Sparse Vector Search (BM25)

í¬ì†Œ ë²¡í„° ê²€ìƒ‰ì€ í‚¤ì›Œë“œ ê¸°ë°˜ì˜ í…ìŠ¤íŠ¸ ê²€ìƒ‰ìœ¼ë¡œ, BM25 ì•Œê³ ë¦¬ì¦˜ì— ê¸°ë°˜í•œë‹¤. `FastEmbedSparse`ë¥¼ í†µí•´ sparse vectorë¥¼ ìƒì„±í•˜ë©°, QdrantëŠ” ì´ë¥¼ ë³„ë„ ì¸ë±ìŠ¤ë¡œ ê´€ë¦¬í•œë‹¤.

```python
sparse_store.similarity_search("soccer players", k=1)
```

ì´ ë°©ì‹ì€ ì „í†µì ì¸ ì •ë³´ ê²€ìƒ‰(IR)ê³¼ ìœ ì‚¬í•˜ë©°, ëª…ì‹œì ì¸ í‚¤ì›Œë“œë¥¼ í¬í•¨í•˜ëŠ” ë¬¸ì„œ ê²€ìƒ‰ì— ìœ ë¦¬í•˜ë‹¤.


### 5.3 Hybrid Search

Hybrid ê²€ìƒ‰ì€ Denseì™€ Sparse ê²€ìƒ‰ì„ ë™ì‹œì— ìˆ˜í–‰í•˜ê³ , ìœ ì‚¬ë„ ì ìˆ˜ë¥¼ í†µí•©í•˜ì—¬ ê²°ê³¼ë¥¼ ì •ë ¬í•œë‹¤. ì˜ë¯¸ ê¸°ë°˜ê³¼ í‚¤ì›Œë“œ ê¸°ë°˜ ê²€ìƒ‰ì˜ ì¥ì ì„ ê²°í•©í•œë‹¤.

```python
results = hybrid_vector_store.similarity_search_with_score(
    "Will it be hot tomorrow", k=1
)
```

`RetrievalMode.HYBRID`ë¡œ ì„¤ì • ì‹œ ë‘ ì¢…ë¥˜ì˜ ë²¡í„°ê°€ ëª¨ë‘ ì €ì¥ë˜ê³  ê²€ìƒ‰ ì‹œ í™œìš©ëœë‹¤.


### 5.4 ë©”íƒ€ë°ì´í„° í•„í„°ë§

QdrantëŠ” JSON ê¸°ë°˜ì˜ Payloadì— ëŒ€í•´ í•„í„°ë§ ê¸°ëŠ¥ì„ ì œê³µí•˜ë©°, LangChainì—ì„œë„ ì´ë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆë‹¤. íŠ¹ì • í‚¤ ë˜ëŠ” ê°’ ê¸°ì¤€ìœ¼ë¡œ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì œí•œí•  ìˆ˜ ìˆë‹¤.

```python
filter=models.Filter(
    should=[
        models.FieldCondition(
            key="page_content",
            match=models.MatchValue(value="The top 10 soccer players in the world right now.")
        )
    ]
)
```

ì´ëŠ” Faceted Search ë˜ëŠ” ì¡°ê±´ ê¸°ë°˜ í•„í„°ë§ì´ í•„ìš”í•œ RAG íŒŒì´í”„ë¼ì¸ì—ì„œ ë§¤ìš° ìœ ìš©í•˜ë‹¤.


### 5.5 ë¬¸ì„œ ì‚­ì œ

ì¶”ê°€ëœ ë¬¸ì„œëŠ” UUIDë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì œê±°í•  ìˆ˜ ìˆë‹¤. í•´ë‹¹ ê¸°ëŠ¥ì€ ë¬¸ì„œ ê°±ì‹  ë˜ëŠ” RAG ë¬¸ë§¥ ê´€ë¦¬ ì‹œ ìœ ìš©í•˜ê²Œ í™œìš©ëœë‹¤.

```python
hybrid_vector_store.delete(ids=[target_id])
```


### 5.6 Retriever ë³€í™˜

`QdrantVectorStore`ëŠ” `.as_retriever()` ë©”ì„œë“œë¥¼ í†µí•´ LangChainì˜ `Retriever`ë¡œ ë³€í™˜í•  ìˆ˜ ìˆë‹¤. ë³€í™˜ëœ RetrieverëŠ” LLM ì²´ì¸ ë˜ëŠ” Agent ë‚´ë¶€ì—ì„œ ì§ì ‘ ì‚¬ìš© ê°€ëŠ¥í•˜ë‹¤.

```python
retriever = hybrid_vector_store.as_retriever(search_type="mmr", search_kwargs={"k": 1})
docs = retriever.invoke("Stealing from the bank is a crime")
```

MMR(Maximal Marginal Relevance)ì„ í™œìš©í•˜ë©´ ë‹¤ì–‘í•œ ê´€ì ì˜ ë¬¸ì„œë¥¼ í˜¼í•©í•´ ë°˜í™˜í•  ìˆ˜ ìˆë‹¤.


### 5.7 Named Vector ë° ì»¤ìŠ¤í…€ Payload í‚¤ í™œìš©

QdrantëŠ” ë™ì¼í•œ ë¬¸ì„œì— ì—¬ëŸ¬ named vectorë¥¼ ì €ì¥í•  ìˆ˜ ìˆë‹¤. ë˜í•œ `page_content`, `metadata` ì™¸ì— ì»¤ìŠ¤í…€ í‚¤ë¡œë„ ì €ì¥í•  ìˆ˜ ìˆë‹¤.

```python
QdrantVectorStore.from_documents(
    docs,
    embeddings,
    sparse_embedding=sparse_embeddings,
    location=":memory:",
    collection_name="my_documents_custom",
    content_payload_key="my_page_content",
    metadata_payload_key="my_meta",
    vector_name="custom_vector",
    sparse_vector_name="custom_sparse_vector",
    retrieval_mode=RetrievalMode.HYBRID,
)
```

ì´ëŠ” ì™¸ë¶€ì—ì„œ ìƒì„±ëœ Qdrant ì»¬ë ‰ì…˜ì„ LangChainì— ê·¸ëŒ€ë¡œ ì—°ê²°í•  ë•Œ ë§¤ìš° ìœ ìš©í•˜ë‹¤.


## 6. ê²°ë¡ 

QdrantëŠ” LangChainê³¼ì˜ í†µí•©ì„ í†µí•´ ë‹¤ì–‘í•œ ê²€ìƒ‰ ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ìœ ì—°í•˜ê²Œ ì§€ì›í•˜ë©°, Dense, Sparse, Hybrid ê²€ìƒ‰ ëª¨ë“œë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•˜ëŠ” ê°•ë ¥í•œ RAG ì‹œìŠ¤í…œ êµ¬ì¶•ì´ ê°€ëŠ¥í•˜ë‹¤. ë©”íƒ€ë°ì´í„° ê¸°ë°˜ í•„í„°ë§, ë‹¤ì¤‘ ë²¡í„° ì €ì¥, ë¬¸ì„œ ì‚­ì œ ë° Retriever ë³€í™˜ê¹Œì§€ í¬í•¨í•œ ì „ì²´ ê¸°ëŠ¥ì„ ì†ì‰½ê²Œ í™œìš©í•  ìˆ˜ ìˆë‹¤.

Qdrant + LangChainì€ ë‹¨ìˆœí•œ ë²¡í„° DB ê·¸ ì´ìƒìœ¼ë¡œ, LLM ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ìœ„í•œ ì‹¤ì§ˆì ì¸ ê²€ìƒ‰/ë¦¬íŠ¸ë¦¬ë²Œ ì¸í”„ë¼ë¡œ ì‚¬ìš©ë  ìˆ˜ ìˆë‹¤.